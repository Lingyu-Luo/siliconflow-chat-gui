import streamlit as st
import os
import json
import re
from datetime import datetime
import base64
import requests

# é…ç½®åŸºç¡€ä¿¡æ¯
headers = {
    "Authorization": f"Bearer {os.getenv('SILICONFLOW_API_KEY')}",
    "Content-Type": "application/json"
}

# å¸¸é‡å®šä¹‰
HISTORY_DIR = "ChatHistory"
MEMORY_FILE = "memories.json"
NUM_CONVO_DISPLAY = 10
BASE_URL = "https://api.siliconflow.cn/v1/chat/completions"
NAME_MODEL = "deepseek-ai/DeepSeek-V3.1"
VLM_MODEL = "zai-org/GLM-4.5V"
VLM_MAX_TOKENS = "8192"

# ç™½åå•å¤„ç†æ··åˆæ¨ç†
HYBRID_MODEL_LIST = [
    "deepseek-ai/DeepSeek-V3.1",
    "Pro/deepseek-ai/DeepSeek-V3.1",
    "zai-org/GLM-4.5V"
]

# ç¡®ä¿å†å²ç›®å½•å­˜åœ¨
os.makedirs(HISTORY_DIR, exist_ok=True)


class SessionManager:
    """ç®¡ç†ä¼šè¯çŠ¶æ€çš„ç±»"""

    @staticmethod
    def init_session():
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'current_convo' not in st.session_state:
            st.session_state.current_convo = None
        if 'convo_list' not in st.session_state:
            st.session_state.convo_list = []
        if 'num_convo_display' not in st.session_state:
            st.session_state.num_convo_display = 10
        # æ–°å¢æ¨¡å‹å‚æ•°åˆå§‹åŒ–
        if 'selected_model' not in st.session_state:
            st.session_state.selected_model = "deepseek-ai/DeepSeek-R1"
        if 'max_tokens' not in st.session_state:
            st.session_state.max_tokens = 2048
        if 'temperature' not in st.session_state:
            st.session_state.temperature = 1.0
        if 'top_p' not in st.session_state:
            st.session_state.top_p = 1.0
        if 'enable_web_search' not in st.session_state:
            st.session_state.enable_web_search = False

        # å†å²è®°å½•å…¼å®¹ï¼ˆå¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯ï¼‰
        for msg in st.session_state.get('messages', []):
            if isinstance(msg.get("content"), list):
                for item in msg["content"]:
                    if item["type"] == "image_url":
                        item["image_url"]["url"] = str(item["image_url"]["url"])


class FileManager:
    """ç®¡ç†æ–‡ä»¶æ“ä½œçš„ç±»"""

    @staticmethod
    def generate_filename(content):
        """ç”Ÿæˆå¯¹è¯æ–‡ä»¶å"""
        # æå–æ–‡æœ¬å†…å®¹ç”¨äºç”Ÿæˆæ–‡ä»¶å
        text_content = ""
        if isinstance(content, list):
            texts = [item["text"] for item in content if isinstance(item, dict) and item.get("type") == "text"]
            text_content = " ".join(texts)
        else:
            text_content = str(content)

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¯¹è¯å‘½ååŠ©æ‰‹ï¼Œå¸®åŠ©æå–å¯¹è¯å…³é”®è¯ä½œä¸ºå¯¹è¯è®°å½•æ–‡ä»¶åï¼Œåäº”å­—ä»¥å†…ã€‚"},
            {"role": "user", "content": "æå–å¯¹è¯çš„ä¸»é¢˜ï¼ˆä»…è¾“å‡ºä¸»é¢˜æœ¬èº«ï¼‰ï¼š" + text_content}
        ]

        payload = ApiManager.make_payload(NAME_MODEL, messages, enable_thinking=False, stream=False)
        response = requests.post(BASE_URL, json=payload, headers=headers)

        clean_content = (response.json())["choices"][0]["message"].get("content", "").strip()
        clean_content = re.sub(r'[\n\r\t\\/*?:"<>|]', "", clean_content)[:15]
        timestamp = datetime.now().strftime("%m%d%H%M")
        return f"{timestamp}_{clean_content}.json" if clean_content else f"{timestamp}_æœªå‘½å.json"

    @staticmethod
    def refresh_convo_list():
        """åˆ·æ–°å¯¹è¯åˆ—è¡¨"""
        st.session_state.convo_list = [
            f for f in os.listdir(HISTORY_DIR)
            if f.endswith('.json') and os.path.getsize(os.path.join(HISTORY_DIR, f)) > 0
        ]
        st.session_state.convo_list.reverse()

    @staticmethod
    def new_conversation():
        """åˆ›å»ºæ–°å¯¹è¯"""
        st.session_state.messages = []
        st.session_state.current_convo = None

    @staticmethod
    def load_conversation(filename):
        """åŠ è½½å¯¹è¯"""
        path = os.path.join(HISTORY_DIR, filename)
        with open(path, 'r', encoding='utf-8') as f:
            st.session_state.messages = json.load(f)
        st.session_state.current_convo = filename

    @staticmethod
    def save_conversation():
        """ä¿å­˜å¯¹è¯"""
        if st.session_state.current_convo and st.session_state.messages:
            path = os.path.join(HISTORY_DIR, st.session_state.current_convo)
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(st.session_state.messages, f, ensure_ascii=False, indent=2)


class ApiManager:
    """ç®¡ç†APIç›¸å…³æ“ä½œçš„ç±»"""

    @staticmethod
    def make_payload(model: str, messages: list, enable_thinking: bool | None = None, stream: bool = True):
        """æ„å»ºè¯·æ±‚è´Ÿè½½"""
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": st.session_state.max_tokens,
            "temperature": st.session_state.temperature,
            "top_p": st.session_state.top_p,
            "stream": stream
        }

        if enable_thinking is not None and model in HYBRID_MODEL_LIST:
            payload["enable_thinking"] = enable_thinking

        return payload

    @staticmethod
    def convert_messages_for_api(messages, use_vlm):
        """è½¬æ¢æ¶ˆæ¯æ ¼å¼é€‚é…ä¸åŒæ¨¡å‹"""
        converted = []
        for msg in messages:
            if use_vlm:
                if isinstance(msg["content"], list):
                    content = []
                    for item in msg["content"]:
                        if item["type"] in ["text", "image_url"]:  # åªä¿ç•™è¿™ä¸¤ç§ç±»å‹
                            content_item = {"type": item["type"]}
                            if item["type"] == "image_url":
                                content_item["image_url"] = {"url": item["image_url"]["url"]}
                            elif item["type"] == "text":
                                content_item["text"] = item.get("text", "")
                            content.append(content_item)
                else:
                    content = [{"type": "text", "text": str(msg["content"])}]
            else:
                if isinstance(msg["content"], list):
                    ref_text = ""
                    content = ""
                    for item in msg["content"]:
                        if item.get("type") == "reference":
                            ref_text = "\n\nã€ç›¸å…³å‚è€ƒèµ„æ–™ã€‘\n"
                            for i, ref in enumerate(item.get("reference", [])):
                                ref_text += f"{i + 1}. {ref.get('content', '')[:4096]}\n\næ¥æºï¼š{ref.get('title', 'æ— æ ‡é¢˜')} ({ref.get('link', 'æ— é“¾æ¥')})\n\n"
                    if ref_text:
                        content = ref_text + "åŸè¾“å…¥ï¼š\n"
                    text_parts = [item["text"] for item in msg["content"] if item.get("type") == "text"]
                    content += " ".join(text_parts)
                else:
                    content = msg["content"]
            converted.append({"role": msg["role"], "content": content})
        return converted

    @staticmethod
    def send_request(model, messages, use_vlm=False):
        """å‘é€APIè¯·æ±‚å¹¶å¤„ç†å“åº”"""
        try:
            api_messages = ApiManager.convert_messages_for_api(messages, use_vlm)
            payload = ApiManager.make_payload(
                model=model, 
                messages=api_messages, 
                enable_thinking=True if model in HYBRID_MODEL_LIST else None
            )

            print("æ­£åœ¨å‘é€apiè¯·æ±‚...")
            response = requests.post(BASE_URL, json=payload, headers=headers, stream=True)
            return response
        except Exception as e:
            st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
            return None


class UIManager:
    """ç®¡ç†UIç›¸å…³æ“ä½œçš„ç±»"""

    @staticmethod
    def render_with_latex(text: str):
        """æ¸²æŸ“åŒ…å«LaTeXçš„æ–‡æœ¬"""
        text = text.replace(r'\\', r"\\")
        text = text.replace(r'$', r"$")
        text = text.replace(r'$', r"$")
        text = text.replace(r'$$', r"$$")
        text = text.replace(r'$$', r"$$")
        st.markdown(text)

    @staticmethod
    def display_message(msg):
        """æ˜¾ç¤ºæ¶ˆæ¯"""
        avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
        with st.chat_message(msg["role"], avatar=avatar):
            # å…ˆæ˜¾ç¤ºæ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            if msg["role"] == "assistant" and msg.get("reasoning"):
                with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹ï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                    UIManager.render_with_latex(msg["reasoning"])

            # å†æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
            if isinstance(msg["content"], list):
                for item in msg["content"]:
                    if item["type"] == "image_url":
                        try:
                            base64_str = item["image_url"]["url"].split(",")[1]
                            st.image(base64.b64decode(base64_str), use_container_width=True)
                        except:
                            st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
                    elif item["type"] == "text" and item["text"].strip():
                        UIManager.render_with_latex(item["text"])
                    elif item["type"] == "reference":
                        with st.expander("ğŸ“š å‚è€ƒæ¥æºï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                            for i, ref in enumerate(item["reference"]):
                                st.caption(f"å‚è€ƒèµ„æ–™ {i + 1}")
                                UIManager.render_with_latex(f"```\n{ref['content']}\n```")
                                if 'title' and 'link' in ref:
                                    st.caption(f"{ref['title']}\n{ref['link']}")
            else:
                UIManager.render_with_latex(msg["content"])

    @staticmethod
    def render_sidebar():
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.title("å¯¹è¯ç®¡ç†")

        # æ¨¡å‹è®¾ç½®åŒºåŸŸ
        st.subheader("æ¨¡å‹è®¾ç½®")
        st.session_state.selected_model = st.selectbox(
            "é€‰æ‹©å¯¹è¯æ¨¡å‹",
            ["deepseek-ai/DeepSeek-V3.1",
             "Qwen/Qwen3-235B-A22B-Thinking-2507",
             "zai-org/GLM-4.5",
             "Pro/deepseek-ai/DeepSeek-V3.1"],
            index=0
        )

        # å‚æ•°è°ƒèŠ‚éƒ¨åˆ†
        col1, col2 = st.columns([3, 1])
        with col1:
            st.session_state.max_tokens = st.slider(
                "æœ€å¤§ç”Ÿæˆé•¿åº¦ (max_tokens)",
                8192, 163840, 16384,
                help="æ§åˆ¶ç”Ÿæˆå†…å®¹çš„æœ€å¤§é•¿åº¦"
            )
        with col2:
            st.session_state.max_tokens = st.number_input(
                "è¾“å…¥å€¼",
                min_value=8192,
                max_value=163840,
                value=16384,
                step=512,
                key="max_tokens_input"
            )

        col1, col2 = st.columns([3, 1])
        with col1:
            st.session_state.temperature = st.slider(
                "åˆ›é€ æ€§ (temperature)",
                0.0, 2.0, 0.6, 0.1,
                help="å€¼è¶Šå¤§ç”Ÿæˆå†…å®¹è¶Šéšæœº"
            )
        with col2:
            st.session_state.temperature = st.number_input(
                "è¾“å…¥å€¼",
                min_value=0.0,
                max_value=2.0,
                value=0.6,
                step=0.1,
                key="temp_input",
                format="%.1f"
            )

        col1, col2 = st.columns([3, 1])
        with col1:
            st.session_state.top_p = st.slider(
                "æ ¸å¿ƒé‡‡æ · (top_p)",
                0.0, 1.0, 0.95, 0.01,
                help="æ§åˆ¶ç”Ÿæˆå†…å®¹çš„å¤šæ ·æ€§"
            )
        with col2:
            st.session_state.top_p = st.number_input(
                "è¾“å…¥å€¼",
                min_value=0.0,
                max_value=1.0,
                value=0.95,
                step=0.01,
                key="top_p_input",
                format="%.2f"
            )

        if st.button("â• æ–°å»ºå¯¹è¯", use_container_width=True):
            FileManager.new_conversation()
            st.rerun()

        st.subheader("å†å²å¯¹è¯")
        FileManager.refresh_convo_list()
        convo_render_list = st.session_state.convo_list[:st.session_state.num_convo_display]
        for convo in convo_render_list:
            cols = st.columns([3, 1])
            with cols[0]:
                if st.button(convo[:-5], key=f"btn_{convo}", use_container_width=True):
                    FileManager.load_conversation(convo)
                    st.rerun()
            with cols[1]:
                if st.button("Ã—", key=f"del_{convo}", type='primary'):
                    os.remove(os.path.join(HISTORY_DIR, convo))
                    if st.session_state.current_convo == convo:
                        FileManager.new_conversation()
                    st.rerun()
        if st.session_state.num_convo_display < len(st.session_state.convo_list):
            if st.button("åŠ è½½æ›´å¤š...", key="load_more_convo"):
                st.session_state.num_convo_display += 10
                st.rerun()

    @staticmethod
    def process_user_input():
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        uploaded_files = st.file_uploader(
            "ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=["png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="file_uploader"
        )

        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æè¿°..."):
            # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
            message_content = []

            # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
            for uploaded_file in uploaded_files:
                if uploaded_file:
                    base64_str = base64.b64encode(uploaded_file.read()).decode("utf-8")
                    mime_type = uploaded_file.type
                    message_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{base64_str}"
                        }
                    })
                    uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ

            # å¤„ç†æ–‡æœ¬è¾“å…¥
            if prompt.strip():
                message_content.append({
                    "type": "text",
                    "text": prompt.strip()
                })

            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            user_message = {
                "role": "user",
                "content": message_content if len(message_content) > 1 else prompt
            }
            st.session_state.messages.append(user_message)

            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user", avatar="ğŸ§‘"):
                for item in message_content:
                    if item["type"] == "image_url":
                        try:
                            base64_str = item["image_url"]["url"].split(",")[1]
                            st.image(base64.b64decode(base64_str), use_container_width=True)
                        except:
                            st.error("å›¾ç‰‡æ˜¾ç¤ºå¤±è´¥")
                    elif item["type"] == "text":
                        UIManager.render_with_latex(item["text"])

            # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
            use_vlm = any(
                isinstance(msg.get("content"), list) and
                any(item.get("type") == "image_url" for item in msg.get("content", []))
                for msg in st.session_state.messages[-1:]
            )

            # å‡†å¤‡APIè¯·æ±‚
            try:
                with st.chat_message("assistant", avatar="ğŸ¤–ï¸"):
                    reasoning_placeholder = st.empty()
                    answer_placeholder = st.empty()
                    full_reasoning = ""
                    full_answer = ""

                    # å‘é€APIè¯·æ±‚
                    model = VLM_MODEL if use_vlm else st.session_state.selected_model
                    response = ApiManager.send_request(model, st.session_state.messages, use_vlm)

                    if response is None:
                        return

                    # å¤„ç†æµå¼å“åº”
                    for chunk in response.iter_lines():
                        if chunk:
                            chunk_str = chunk.decode('utf-8').replace('data: ', '')
                            if chunk_str != "[DONE]":
                                try:
                                    chunk_data = json.loads(chunk_str)
                                except json.JSONDecodeError:
                                    continue
                                delta = chunk_data.get('choices', [{}])[0].get('delta', {})
                                content = delta.get('content', '')
                                reasoning_content = delta.get('reasoning_content', '')
                                if content:
                                    full_answer += content
                                    with answer_placeholder:
                                        UIManager.render_with_latex(full_answer + "â–Œ")
                                if reasoning_content:
                                    full_reasoning += reasoning_content
                                    if full_reasoning.strip():
                                        with reasoning_placeholder.expander("ğŸ¤” å®æ—¶æ¨ç†"):
                                            UIManager.render_with_latex(full_reasoning)
                    print("å“åº”æ¥å—å®Œæˆã€‚")

                    # ä¿å­˜æœ€ç»ˆå“åº”
                    with reasoning_placeholder:
                        if full_reasoning.strip():
                            with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹"):
                                UIManager.render_with_latex(full_reasoning.strip())
                    with answer_placeholder:
                        UIManager.render_with_latex(full_answer)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": full_answer,
                        "reasoning": full_reasoning.strip()
                    })

            except Exception as e:
                st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "å“åº”ç”Ÿæˆå¤±è´¥",
                    "reasoning": f"é”™è¯¯ä¿¡æ¯: {str(e)}"
                })

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä¼˜å…ˆä½¿ç”¨æ–‡æœ¬å†…å®¹ï¼‰
            filename_content = prompt.strip()
            if not st.session_state.current_convo:
                print("æ­£åœ¨ç”Ÿæˆå¯¹è¯æ–‡ä»¶å...")
                st.session_state.current_convo = FileManager.generate_filename(filename_content)
            # ä¿å­˜å¯¹è¯è®°å½•
            if st.session_state.current_convo:
                FileManager.save_conversation()
                FileManager.refresh_convo_list()
            print("\n")


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ä¼šè¯
    SessionManager.init_session()

    # ä¾§è¾¹æ å¸ƒå±€
    with st.sidebar:
        UIManager.render_sidebar()

    # ä¸»ç•Œé¢å¸ƒå±€
    st.title("æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ï¼ˆæ”¯æŒå›¾æ–‡ï¼‰")

    # æ˜¾ç¤ºèŠå¤©è®°å½•ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
    for msg in st.session_state.messages:
        UIManager.display_message(msg)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    UIManager.process_user_input()

    # è‡ªåŠ¨æ»šåŠ¨å’Œä¿å­˜åŠŸèƒ½
    st.markdown("""
    <script>
    // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    window.addEventListener('DOMContentLoaded', () => {
        const scrollToBottom = () => {
            window.scrollTo(0, document.body.scrollHeight);
        };
        scrollToBottom();
    });
    </script>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()